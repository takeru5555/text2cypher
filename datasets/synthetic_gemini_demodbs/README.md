# Synthetic dataset created with Gemini 1.5 Pro

Synthetic dataset of text2cypher over 16 different graph schemas.

Questions and the corresponding Cypher statements were generated with Gemini 1.5 Pro using the Chain of Thought approach.
The demo database is available at:

```
URI: neo4j+s://demo.neo4jlabs.com
username: name of the database, for example 'movies'
password: name of the database, for example 'movies'
database: name of the database, for example 'movies'
```

Notebooks:

* `generate_questions.ipynb`: Generate questions for each of the databases
* `gemini_text2cypher.ipynb`: Generate Cypher statements and examine if they return any values, have syntax errors, or do queries timeout.

Dataset is available at `text2cypher_gemini.csv`. Columns are the following:

* `question`: Natural language question
* `cypher`: Corresponding Cypher statement based on the provided question
* `type`: Type of question
* `database`: Database that the questions is aimed at
* `syntax_error`: Does the Cypher statement result in Cypher syntax error
* `timeout`: Does the Cypher statement take more than 10 seconds to complete
* `returns_results`: Does the Cypher statement return non-null results
* `no_cypher`: Does the LLM decide that the graph schema doesn't contain information to answer the question

## Potential Tasks and Uses of the Dataset

This synthetic dataset can be utilized for various research and development tasks, including:

* Evaluating Syntax Errors: Analyze and categorize the types of syntax errors generated by the LLM to improve error handling and debugging capabilities in Cypher statement generation.
* Detecting Schema Hallucination: Evaluate instances when the LLM hallucinates graph schema elements that do not exist in the database, aiding in the improvement of schema-aware model training.
* Benchmarking LLM Performance: Use the dataset to evaluate the performance of different LLMs in generating valid Cypher queries, providing insights into model capabilities and limitations.
* Finetuning LLMs: Leverage the dataset for finetuning LLMs on domain-specific languages like Cypher to enhance their accuracy and efficiency in generating database queries.
* Prompt engineering: Determine which prompt produces the most accurate Cypher statements.
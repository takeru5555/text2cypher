# Synthetic dataset created with GPT-4o

Synthetic dataset of text2cypher over 16 different graph schemas.

Questions were generated using GPT-4-turbo, and the corresponding Cypher statements with `gpt-4o` using Chain of Thought.
The demo database is available at:

```
URI: neo4j+s://demo.neo4jlabs.com
username: name of the database, for example 'movies'
password: name of the database, for example 'movies'
database: name of the database, for example 'movies'
```

Notebooks:

* `generate_batch_input.ipynb`: Prepare input for OpenAI batch processing job
* `process_batch_output.ipynb`: Process batch process output and validate the generate Cypher statements by examining if they return any values, have syntax errors, or do queries timeout.

Dataset is available at `text2cypher_gpt4o.csv`. Columns are the following:

* `question`: Natural language question
* `cypher`: Corresponding Cypher statement based on the provided question
* `type`: Type of question, see `synthetic_gpt4turbo_demodbs/generate_text2cypher_questions.ipynb` for more information
* `database`: Database that the questions is aimed at
* `syntax_error`: Does the Cypher statement result in Cypher syntax error
* `timeout`: Does the Cypher statement take more than 10 seconds to complete
* `returns_results`: Does the Cypher statement return non-null results
* `no_cypher`: Does the LLM decide that the graph schema doesn't contain information to answer the question

## Potential Tasks and Uses of the Dataset

This synthetic dataset can be utilized for various research and development tasks, including:

* Evaluating Syntax Errors: Analyze and categorize the types of syntax errors generated by the LLM to improve error handling and debugging capabilities in Cypher statement generation.
* Detecting Schema Hallucination: Evaluate instances when the LLM hallucinates graph schema elements that do not exist in the database, aiding in the improvement of schema-aware model training.
* Benchmarking LLM Performance: Use the dataset to evaluate the performance of different LLMs in generating valid Cypher queries, providing insights into model capabilities and limitations.
* Finetuning LLMs: Leverage the dataset for finetuning LLMs on domain-specific languages like Cypher to enhance their accuracy and efficiency in generating database queries.
* Prompt engineering: Determine which prompt produces the most accurate Cypher statements.
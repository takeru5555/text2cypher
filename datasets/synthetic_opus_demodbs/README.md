# Synthetic dataset created with Claude Opus

Synthetic dataset of text2cypher over 7 different graph schemas.

Questions were generated using GPT-4-turbo, and the corresponding Cypher statements with `claude-3-opus-20240229`.
The demo database is available at:

```
URI: neo4j+s://demo.neo4jlabs.com
username: name of the database, for example 'movies'
password: name of the database, for example 'movies'
database: name of the database, for example 'movies'
```

Notebooks:

* `anthropic_text2cypher.ipynb`: Generate Cypher statements and validate them by examining if they return any values, have syntax errors, or do queries timeout.

Dataset is available at `text2cypher_claudeopus.csv`. Columns are the following:

* `question`: Natural language question
* `cypher`: Corresponding Cypher statement based on the provided question
* `type`: Type of question, see `synthetic_gpt4turbo_demodbs/generate_text2cypher_questions.ipynb` for more information
* `database`: Database that the questions is aimed at
* `syntax_error`: Does the Cypher statement result in Cypher syntax error
* `timeout`: Does the Cypher statement take more than 10 seconds to complete
* `returns_results`: Does the Cypher statement return non-null results
* `false_schema`: Does the Cypher statement uses parts of graph schema (node types or properties) that aren't present in the graph

## Potential Tasks and Uses of the Dataset

This synthetic dataset can be utilized for various research and development tasks, including:

* Evaluating Syntax Errors: Analyze and categorize the types of syntax errors generated by the LLM to improve error handling and debugging capabilities in Cypher statement generation.
* Detecting Schema Hallucination: Evaluate instances when the LLM hallucinates graph schema elements that do not exist in the database, aiding in the improvement of schema-aware model training.
* Benchmarking LLM Performance: Use the dataset to evaluate the performance of different LLMs in generating valid Cypher queries, providing insights into model capabilities and limitations.
* Finetuning LLMs: Leverage the dataset for finetuning LLMs on domain-specific languages like Cypher to enhance their accuracy and efficiency in generating database queries.
* Prompt engineering: Determine which prompt produces the most accurate Cypher statements.
* Comparing accuracy and limitations between Opus and GPT-4-Turbo